#!/usr/bin/env python3
"""Update grades_summary.json from repos-management/grades_summary.toml.

Schema (per course/year/variant grade entry):
  grade = {
    "raw": <original string>,
    "items": [ {"name": <str>, "percent": <str>} ... ],
    "note": <str | null>
  }

Rationale:
- Always preserves the original text in `raw`.
- Provides a structured list in `items` when parseable.
- Captures any leftover/annotation text in `note`.
"""

from __future__ import annotations

import json
import re
import tomllib
import urllib.request
from pathlib import Path
from typing import Any

SOURCE_URL = (
    "https://raw.githubusercontent.com/HITSZ-OpenAuto/repos-management/main/grades_summary.toml"
)
OUT_PATH = Path(__file__).resolve().parents[1] / "src/hoa_majors/data/grades_summary.json"

PERCENT_RE = re.compile(r"(\d+%)")


def normalize_entry_key(course_variant: str) -> str:
    """Normalize TOML variant keys into one of:

    - default
    - 入学年份_default (e.g. 2024_default)
    - 入学年份_专业 (e.g. 2022_自动化)

    Notes:
    - Keys like "23级" / "21级自动化" are converted to 2023_* / 2021_*.
    - A few variants in upstream data are not enrollment-year based (e.g. teacher names).
      We currently map them into "default" (see PR discussion if this needs refinement).
    """

    if course_variant == "default":
        return "default"

    # Plain year.
    if re.fullmatch(r"\d{4}", course_variant):
        return f"{course_variant}_default"

    # Patterns like "23级" / "21级自动化".
    m = re.fullmatch(r"(?P<yy>\d{2})级(?P<rest>.*)", course_variant)
    if m:
        year = f"20{m.group('yy')}"
        rest = m.group("rest").strip()
        if not rest:
            return f"{year}_default"
        return f"{year}_{rest}"

    # Non-year variants in the upstream file.
    return "default"


def parse_grade(raw: str) -> dict[str, Any]:
    """Parse a grade string into a structured object.

    We aim for best-effort parsing while keeping raw text intact.
    """

    raw_norm = raw.replace("＋", "+")

    # Split on '+' only when it likely separates components.
    # - "... 30%+ ..." (plus right after a percent)
    # - "... + ..." (plus surrounded by whitespace)
    # This avoids splitting merged names like "作业+实验 50%".
    split_re = r"(?<=%)\s*\+\s*|\s+\+\s+"
    parts = [p.strip() for p in re.split(split_re, raw_norm) if p.strip()]

    items: list[dict[str, str]] = []
    notes: list[str] = []

    for part in parts or [raw_norm.strip()]:
        m = PERCENT_RE.search(part)
        if not m:
            # Not parseable as a (name, percent) pair.
            notes.append(part)
            continue

        percent = m.group(1)
        name = part[: m.start()].strip()
        tail = part[m.end() :].strip()

        # If the "name" is empty, treat as note to avoid producing nonsense keys.
        if not name:
            notes.append(part)
            continue

        items.append({"name": name, "percent": percent})
        if tail:
            notes.append(tail)

    note = " ".join(n for n in notes if n).strip() or None
    return {"raw": raw, "items": items, "note": note}


def extract_grade_strings(obj: Any) -> list[str]:
    """Collect all grade strings found under a variant block.

    Upstream TOML shapes include:
    - variant -> default -> {grade: "..."}
    - variant -> default -> default -> {grade: "..."}
    """

    out: list[str] = []
    if isinstance(obj, dict):
        for k, v in obj.items():
            if k == "grade" and isinstance(v, str):
                out.append(v)
            else:
                out.extend(extract_grade_strings(v))
    elif isinstance(obj, list):
        for v in obj:
            out.extend(extract_grade_strings(v))
    return out


def main() -> None:
    raw_bytes = urllib.request.urlopen(SOURCE_URL).read()
    toml_data = tomllib.loads(raw_bytes.decode("utf-8"))

    grades = toml_data.get("grades", {})
    out_grades: dict[str, Any] = {}

    for course_code, course_obj in grades.items():
        if not isinstance(course_obj, dict):
            continue

        entries: dict[str, Any] = {}

        for variant_key, variant_obj in course_obj.items():
            if variant_key == "course_name":
                continue  # explicitly removed per repo convention

            entry_key = normalize_entry_key(str(variant_key))
            grade_strings = extract_grade_strings(variant_obj)
            if not grade_strings:
                continue

            # If multiple grade strings appear for the same entry_key, keep the first and
            # append the rest into its note to remain lossless enough.
            first = grade_strings[0]
            grade_struct = parse_grade(first)
            if len(grade_strings) > 1:
                extra = " | ".join(grade_strings[1:])
                grade_struct["note"] = (
                    f"{grade_struct['note']} | {extra}" if grade_struct["note"] else extra
                )

            if entry_key in entries:
                # Merge collision: keep existing and append this raw into note.
                prev = entries[entry_key]["grade"]
                prev_note = prev.get("note")
                prev["note"] = (
                    f"{prev_note} | ALT: {grade_struct['raw']}"
                    if prev_note
                    else f"ALT: {grade_struct['raw']}"
                )
            else:
                entries[entry_key] = {"grade": grade_struct}

        if entries:
            out_grades[course_code] = entries

    out = {"grades": out_grades}

    OUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    OUT_PATH.write_text(
        json.dumps(out, ensure_ascii=False, indent=2, sort_keys=True) + "\n",
        encoding="utf-8",
    )


if __name__ == "__main__":
    main()
